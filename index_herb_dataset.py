#!/usr/bin/env python3
"""index_herb_dataset.py

GitHubì—ì„œ ê³µê°œëœ HERB(Heterogeneous Enterprise RAG Benchmark) ë¦¬í¬ì§€í† ë¦¬ë¥¼
ë¡œì»¬ì— í´ë¡ (clone)í•œ ë’¤, ì œí’ˆ(product) ì•„í‹°íŒ©íŠ¸ JSON íŒŒì¼ì„ LangChain
`Document`ë¡œ ë³€í™˜í•˜ì—¬ `advanced_rag.RagEngine`ì˜ Chroma ì¸ë±ìŠ¤ì— ì €ì¥í•œë‹¤.

ì¥ì 
-----
1. Hugging Face `datasets` ëª¨ë“ˆì˜ Arrow íŒŒì‹± ì˜¤ë¥˜ë¥¼ ìš°íšŒí•œë‹¤.
2. íŒŒì¼ë³„(JSON) íŒŒì‹±ì´ë¯€ë¡œ ìŠ¤í‚¤ë§ˆê°€ ë‹¬ë¼ë„ ì•ˆì „í•˜ë‹¤.
3. ì›í•˜ëŠ” ê°œìˆ˜ë§Œ ìƒ˜í”Œë§í•  ìˆ˜ ìˆì–´ ë¹ ë¥¸ ì‹¤í—˜ ê°€ëŠ¥.

ì‚¬ìš©ë²•
-------
```bash
source .venv/bin/activate
pip install -U -r requirements_enterprise_rag.txt  # json, gitpython ë“± í•„ìš” X

# ì „ì²´ ì¸ë±ì‹± (ìˆ˜ ë¶„)
python index_herb_dataset.py --repo_dir HERB --max_files 0

# ë¹ ë¥¸ ìƒ˜í”Œ(ì˜ˆ: 100íŒŒì¼)ë§Œ ì¸ë±ì‹±
python index_herb_dataset.py --max_files 100
```

Options
-------
--repo_dir      : HERB GitHub ì €ì¥ì†Œ ê²½ë¡œ(ì—†ìœ¼ë©´ ìë™ clone)
--chunk_size    : ì²­í¬ ë¬¸ì ê¸¸ì´ (ê¸°ë³¸ 800)
--chunk_overlap : ì²­í¬ ê²¹ì¹¨ (ê¸°ë³¸ 120)
--max_files     : 0ì´ë©´ ì „ì²´, n>0 ì´ë©´ nê°œ íŒŒì¼ë§Œ ì¸ë±ì‹±
"""
from __future__ import annotations

import argparse
import json
import subprocess
from pathlib import Path
from typing import List

from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter

from advanced_rag import RagEngine

REPO_URL = "https://github.com/SalesforceAIResearch/HERB.git"
DEFAULT_REPO_DIR = Path("HERB")  # ./HERB
DEFAULT_CHUNK_SIZE = 800
DEFAULT_CHUNK_OVERLAP = 120


def ensure_repo(repo_dir: Path):
    """
    HERB GitHub ì €ì¥ì†Œê°€ ë¡œì»¬ì— ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ í´ë¡ 
    
    Args:
        repo_dir: í´ë¡ í•  ë¡œì»¬ ë””ë ‰í† ë¦¬ ê²½ë¡œ
    """
    if repo_dir.exists():
        print(f"âœ… HERB ì €ì¥ì†Œê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {repo_dir}")
        return
    print(f"ğŸ“¥ HERB ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘... {REPO_URL} â†’ {repo_dir}")
    print(f"â³ ì•½ ìˆ˜ì´ˆ~ìˆ˜ë¶„ ì†Œìš” (ë„¤íŠ¸ì›Œí¬ ì†ë„ì— ë”°ë¼ ë‹¤ë¦„)")
    # --depth 1: ìµœì‹  ì»¤ë°‹ë§Œ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì†ë„ í–¥ìƒ
    subprocess.run(["git", "clone", "--depth", "1", REPO_URL, str(repo_dir)], check=True)
    print(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")


def iter_product_files(repo_dir: Path, max_files: int = 0):
    """
    HERB ë°ì´í„°ì…‹ì˜ ì œí’ˆë³„ JSON íŒŒì¼ë“¤ì„ ìˆœíšŒí•˜ëŠ” ì œë„ˆë ˆì´í„°
    
    Args:
        repo_dir: HERB ì €ì¥ì†Œ ë£¨íŠ¸ ë””ë ‰í† ë¦¬
        max_files: ìµœëŒ€ ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜ (0=ì „ì²´, í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì¼ë¶€ë§Œ ì²˜ë¦¬ ê°€ëŠ¥)
        
    Yields:
        Path: ê° ì œí’ˆì˜ JSON íŒŒì¼ ê²½ë¡œ
    """
    products_dir = repo_dir / "data" / "products"        # HERB ì œí’ˆ ë°ì´í„° í´ë”
    print(f"ğŸ“ ì œí’ˆ ë°ì´í„° í´ë” íƒìƒ‰: {products_dir}")
    
    # rglobìœ¼ë¡œ í•˜ìœ„ í´ë”ê¹Œì§€ ì¬ê·€ì ìœ¼ë¡œ JSON íŒŒì¼ ê²€ìƒ‰
    files = sorted(products_dir.rglob("*.json"))
    print(f"ğŸ” ì´ {len(files)}ê°œì˜ JSON íŒŒì¼ ë°œê²¬")
    
    if max_files > 0:
        files = files[:max_files]
        print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ {len(files)}ê°œ íŒŒì¼ë§Œ ì²˜ë¦¬")
        
    for fp in files:
        yield fp


def load_docs_from_file(json_path: Path, splitter) -> List[Document]:
    """
    HERB ì œí’ˆ JSON íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ LangChain Document ê°ì²´ë“¤ë¡œ ë³€í™˜
    
    Args:
        json_path: ì²˜ë¦¬í•  JSON íŒŒì¼ ê²½ë¡œ
        splitter: í…ìŠ¤íŠ¸ ì²­í‚¹ì„ ìœ„í•œ LangChain ë¶„í• ê¸°
        
    Returns:
        List[Document]: ë³€í™˜ëœ ë¬¸ì„œ ê°ì²´ ëª©ë¡ (ì²­í‚¹ í›„)
    """
    try:
        # JSON íŒŒì¼ ì½ê¸° ë° íŒŒì‹±
        data = json.loads(json_path.read_text("utf-8"))
    except Exception as exc:  # noqa: BLE001
        print(f"âš ï¸  JSON íŒŒì‹± ì‹¤íŒ¨: {json_path.name} â†’ ê±´ë„ˆëœ€ (ì›ì¸: {exc})")
        return []

    product_id = json_path.stem                      # íŒŒì¼ëª…ì—ì„œ ì œí’ˆ ID ì¶”ì¶œ
    docs: List[Document] = []                        # ê²°ê³¼ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
    
    # HERB ë°ì´í„°ì…‹ì˜ ì‹¤ì œ ì•„í‹°íŒ©íŠ¸ êµ¬ì¡° ë§¤í•‘
    # ê° ì œí’ˆë§ˆë‹¤ ë‹¤ì–‘í•œ ê¸°ì—…ìš© ë°ì´í„° ìœ í˜•ë“¤ì´ í¬í•¨ë¨
    artifact_types = {
        "slack": "slack_message",               # íŒ€ ë‚´ë¶€ ìŠ¬ë™ ë©”ì‹œì§€
        "documents": "document",                # ì œí’ˆ ë¬¸ì„œ, ìš”êµ¬ì‚¬í•­ ë“± 
        "meeting_transcripts": "meeting_transcript",
        "meeting_chats": "meeting_chat",
        "urls": "url",
        "prs": "pull_request"
    }
    
    for art_key, art_type in artifact_types.items():
        if art_key not in data:
            continue
            
        items = data[art_key]                        # í•´ë‹¹ ìœ í˜•ì˜ ì•„í‹°íŒ©íŠ¸ ë°°ì—´
        if not isinstance(items, list):
            continue  # ë°°ì—´ì´ ì•„ë‹ˆë©´ ê±´ë„ˆëœ€
            
        # ê° ì•„í‹°íŒ©íŠ¸ë¥¼ ìˆœíšŒí•˜ë©° ì²˜ë¦¬
        for idx, item in enumerate(items):
            content = ""                             # ì¶”ì¶œë  í…ìŠ¤íŠ¸ ì»¨í…ì¸ 
            
            # HERBì˜ í—¤í…Œë¡œì§€ë‹ˆì–´ìŠ¤ ìŠ¤í‚¤ë§ˆ: ì•„í‹°íŒ©íŠ¸ ìœ í˜•ë³„ë¡œ ë‹¤ë¥¸ ì¶”ì¶œ ë°©ì‹ ì‚¬ìš©
            if art_key == "slack":
                # ìŠ¬ë™: messages ë°°ì—´ ë‚´ì˜ ê° ë©”ì‹œì§€ì—ì„œ text ì¶”ì¶œ
                if isinstance(item.get("messages"), list):
                    messages_text = []
                    for msg in item["messages"]:
                        if isinstance(msg, dict) and msg.get("text"):
                            messages_text.append(msg["text"])
                    content = "\n".join(messages_text)
            elif art_key == "documents":
                # ë¬¸ì„œ: content ë˜ëŠ” text í•„ë“œì—ì„œ ì»¨í…ì¸  ì¶”ì¶œ
                content = item.get("content") or item.get("text") or ""
            elif art_key in ["meeting_transcripts", "meeting_chats"]:
                # íšŒì˜ ê´€ë ¨: transcript ë˜ëŠ” content í•„ë“œ ì‚¬ìš©
                content = item.get("transcript") or item.get("content") or ""
            else:
                # ê¸°íƒ€ ìœ í˜• (URLs, PRs ë“±): ì¼ë°˜ì ì¸ í•„ë“œë“¤ ì‹œë„
                content = (
                    item.get("content")     # ì¼ë°˜ ì»¨í…ì¸ 
                    or item.get("text")    # í…ìŠ¤íŠ¸ ë‚´ìš©
                    or item.get("description")  # ì„¤ëª…
                    or ""                 # ê¸°ë³¸ê°’
                )
            
            # ë„ˆë¬´ ì§§ê±°ë‚˜ ë¹ˆ ì»¨í…ì¸ ëŠ” ì œì™¸ (RAG íš¨ìœ¨ì„±ì„ ìœ„í•´)
            if not content or len(content.strip()) < 20:
                continue  # ìµœì†Œ 20ì ì´ìƒì˜ ì˜ë¯¸ìˆëŠ” ì»¨í…ì¸ ë§Œ ì‚¬ìš©
                
            # LangChain Documentë¥¼ ìœ„í•œ ë©”íƒ€ë°ì´í„° êµ¬ì„±
            meta = {
                "product_id": product_id,                         # ì œí’ˆ ì‹ë³„ì
                "artifact_type": art_type,                        # ì•„í‹°íŒ©íŠ¸ ìœ í˜• (ìŠ¬ë™, ë¬¸ì„œ ë“±)
                "artifact_id": item.get("id", f"{art_key}_{idx}"), # ê°œë³„ ì•„í‹°íŒ©íŠ¸ ID (ì—†ìœ¼ë©´ ìë™ ìƒì„±)
                "source_file": json_path.name,                    # ì›ë³¸ JSON íŒŒì¼ëª…
                "acl": "*"                                      # ì ‘ê·¼ ì œì–´ (ê¸°ë³¸: ëª¨ë“  ì‚¬ìš©ì í—ˆìš©)
            }
            
            # ê¸´ ì»¨í…ì¸ ë¥¼ ì‘ì€ ì²­í¬ë¡œ ë¶„í•  (RAG ê²€ìƒ‰ íš¨ìœ¨ì„± í–¥ìƒ)
            for chunk in splitter.split_text(content):
                # ê° ì²­í¬ë¥¼ LangChain Documentë¡œ ë³€í™˜í•˜ì—¬ ì¶”ê°€
                docs.append(Document(page_content=chunk, metadata=meta))
    
    return docs  # ì™„ì„±ëœ ë¬¸ì„œ ì²­í¬ ëª©ë¡ ë°˜í™˜


def build_index(repo_dir: Path, chunk_size: int, chunk_overlap: int, max_files: int):
    """
    HERB ë°ì´í„°ì…‹ì„ ì²˜ë¦¬í•˜ì—¬ ChromaDB ë²¡í„° ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•
    
    Args:
        repo_dir: HERB ì €ì¥ì†Œ ë””ë ‰í† ë¦¬
        chunk_size: í…ìŠ¤íŠ¸ ì²­í¬ í¬ê¸° (ë¬¸ì ë‹¨ìœ„)
        chunk_overlap: ì²­í¬ ê°„ ê²¹ì¹¨ í¬ê¸°
        max_files: ì²˜ë¦¬í•  ìµœëŒ€ íŒŒì¼ ìˆ˜ (0=ì „ì²´)
    """
    print(f"ğŸ”§ í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì´ˆê¸°í™”: ì²­í¬={chunk_size}, ê²¹ì¹¨={chunk_overlap}")
    # ì¬ê·€ì  ë¬¸ì ë‹¨ìœ„ í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì •
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,           # ê° ì²­í¬ì˜ ìµœëŒ€ ë¬¸ì ìˆ˜
        chunk_overlap=chunk_overlap,     # ì¸ì ‘ ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¬¸ì ìˆ˜
        separators=["\n\n", "\n", " "], # ë¶„í•  ìš°ì„ ìˆœìœ„: ë‹¨ë½ > ì¤„ë°”ê¿ˆ > ê³µë°±
    )
    
    print(f"ğŸ“¦ ëª¨ë“  JSON íŒŒì¼ì—ì„œ ë¬¸ì„œ ì¶”ì¶œ ì‹œì‘...")
    all_docs: List[Document] = []        # ëª¨ë“  ì²˜ë¦¬ëœ ë¬¸ì„œë“¤ì„ ì €ì¥
    
    # ê° JSON íŒŒì¼ì„ ìˆœíšŒí•˜ë©° ë¬¸ì„œ ì¶”ì¶œ
    for fp in iter_product_files(repo_dir, max_files):
        file_docs = load_docs_from_file(fp, splitter)
        all_docs.extend(file_docs)
        
    print(f"âœ… ì´ {len(all_docs):,}ê°œì˜ Document ì²­í¬ ìƒì„± ì™„ë£Œ")
    
    # ë¹ˆ ê²°ê³¼ ì²˜ë¦¬ (ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ)
    if not all_docs:
        print("âŒ ìˆ˜ì§‘ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. HERB ê²½ë¡œ ë˜ëŠ” JSON ìŠ¤í‚¤ë§ˆë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return

    print(f"ğŸš€ RAG ì—”ì§„ ì´ˆê¸°í™”: ChromaDB ë²¡í„° ì €ì¥ì†Œ ì¤€ë¹„...")
    # HERB ì „ìš© ChromaDB ì»¬ë ‰ì…˜ìœ¼ë¡œ RAG ì—”ì§„ ì´ˆê¸°í™”
    engine = RagEngine(collection_name="herb_collection", persist_dir="./chroma_db")
    
    # ChromaDBì˜ ë°°ì¹˜ í¬ê¸° ì œí•œ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ìˆ˜ë™ ë°°ì¹˜ ì²˜ë¦¬
    BATCH_SIZE = 5000  # í•œ ë²ˆì— ì²˜ë¦¬í•  ìµœëŒ€ ë¬¸ì„œ ìˆ˜
    # ì „ì²´ ë¬¸ì„œë¥¼ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬ (í° ë°ì´í„°ì…‹ ëŒ€ì‘)
    total_batches = (len(all_docs) + BATCH_SIZE - 1) // BATCH_SIZE
    print(f"ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {total_batches}ê°œ ë°°ì¹˜ë¡œ ë¶„í•  ì²˜ë¦¬")
    
    # ê° ë°°ì¹˜ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ë²¡í„° DBì— ì¶”ê°€
    for i in range(0, len(all_docs), BATCH_SIZE):
        batch = all_docs[i:i + BATCH_SIZE]           # í˜„ì¬ ë°°ì¹˜ ì¶”ì¶œ
        batch_num = (i // BATCH_SIZE) + 1            # ë°°ì¹˜ ë²ˆí˜¸ ê³„ì‚°
        print(f"   ğŸ“¦ ë°°ì¹˜ {batch_num}/{total_batches} ì„ë² ë”© ì¤‘... ({len(batch)}ê°œ ë¬¸ì„œ)")
        
        # ChromaDBì— ë²¡í„° ì„ë² ë”© ë° ì €ì¥
        engine.vectordb.add_documents(batch)
    
    # ë””ìŠ¤í¬ì— ì˜êµ¬ ì €ì¥
    engine.vectordb.persist()
    print(f"âœ… HERB ë°ì´í„°ì…‹ ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ! ì €ì¥ ìœ„ì¹˜: ./chroma_db")
    print(f"ğŸ“Š ìµœì¢… í†µê³„: {len(all_docs):,}ê°œ ë¬¸ì„œ ì²­í¬ê°€ ë²¡í„° DBì— ì €ì¥ë¨")


def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜: CLI ì¸ì íŒŒì‹± ë° HERB ë°ì´í„°ì…‹ ì¸ë±ì‹± í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
    """
    print(f"ğŸ” HERB ë°ì´í„°ì…‹ ì¸ë±ì‹± ë„êµ¬ ì‹œì‘")
    print(f"ğŸ† Salesforce AI Research - Heterogeneous Enterprise RAG Benchmark")
    print()
    
    # ëª…ë ¹ì¤„ ì¸ì ì„¤ì •
    parser = argparse.ArgumentParser(
        description="HERB GitHub ë°ì´í„°ì…‹ì„ ChromaDB ë²¡í„° ì¸ë±ìŠ¤ë¡œ ë³€í™˜",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python index_herb_dataset.py                    # ì „ì²´ ë°ì´í„°ì…‹ ì¸ë±ì‹±
  python index_herb_dataset.py --max_files 50    # í…ŒìŠ¤íŠ¸ìš© 50ê°œ íŒŒì¼ë§Œ
  python index_herb_dataset.py --chunk_size 1000  # ì²­í¬ í¬ê¸° ì¡°ì ˆ
        """
    )
    parser.add_argument("--repo_dir", type=Path, default=DEFAULT_REPO_DIR, 
                        help=f"HERB ì €ì¥ì†Œ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: {DEFAULT_REPO_DIR})")
    parser.add_argument("--chunk_size", type=int, default=DEFAULT_CHUNK_SIZE,
                        help=f"í…ìŠ¤íŠ¸ ì²­í¬ í¬ê¸° (ê¸°ë³¸: {DEFAULT_CHUNK_SIZE})")
    parser.add_argument("--chunk_overlap", type=int, default=DEFAULT_CHUNK_OVERLAP,
                        help=f"ì²­í¬ ê°„ ê²¹ì¹¨ í¬ê¸° (ê¸°ë³¸: {DEFAULT_CHUNK_OVERLAP})")
    parser.add_argument("--max_files", type=int, default=0, 
                        help="ì²˜ë¦¬í•  ìµœëŒ€ íŒŒì¼ ìˆ˜ (0=ì „ì²´, n>0=nê°œ íŒŒì¼ë§Œ í…ŒìŠ¤íŠ¸ìš©)")
    
    args = parser.parse_args()

    print(f"âš™ï¸  ì„¤ì •ê°’:")
    print(f"   - HERB ë””ë ‰í† ë¦¬: {args.repo_dir}")
    print(f"   - ì²­í¬ í¬ê¸°: {args.chunk_size} ë¬¸ì")
    print(f"   - ì²­í¬ ê²¹ì¹¨: {args.chunk_overlap} ë¬¸ì")
    print(f"   - ì²˜ë¦¬ íŒŒì¼ ìˆ˜: {'ì „ì²´' if args.max_files == 0 else f'{args.max_files}ê°œ'}")
    print()

    # ë‹¨ê³„ë³„ ì‹¤í–‰
    ensure_repo(args.repo_dir)      # 1ë‹¨ê³„: HERB ì €ì¥ì†Œ í´ë¡  í™•ì¸
    build_index(args.repo_dir, args.chunk_size, args.chunk_overlap, args.max_files)  # 2ë‹¨ê³„: ì¸ë±ìŠ¤ êµ¬ì¶•
    
    print()
    print(f"ğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print(f"ğŸš€ ì´ì œ 'python advanced_rag.py query \"ì§ˆë¬¸\"' ëª…ë ¹ìœ¼ë¡œ RAG ì‹œìŠ¤í…œì„ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”!")


if __name__ == "__main__":
    # ìŠ¤í¬ë¦½íŠ¸ê°€ ì§ì ‘ ì‹¤í–‰ë  ë•Œë§Œ ë©”ì¸ í•¨ìˆ˜ í˜¸ì¶œ
    main()
